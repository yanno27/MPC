{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846757d0",
   "metadata": {},
   "source": [
    "# Exercise 8 | Nonlinear Model Predictive Control\n",
    "\n",
    "Consider a slot car racing track described by the 2D curve $(x(\\lambda),y(\\lambda))\\in\\mathbb{R}^2$ parametrized by the progress variable $\\lambda\\in\\mathbb{R}$. The position of the car is entirely determined by $\\lambda$ and its velocity by $v=\\dot{\\lambda}$, allowing us to model it using the state $x=(\\lambda, v)$.\n",
    "\n",
    "The curvature of the track is given by a function $\\kappa(\\lambda)$ and the car is know to flip out from the track if the speed $v$ exceeds $\\frac{1}{1+\\kappa(\\lambda)}$.\n",
    "\n",
    "The car actuation can be modeled using an acceleration input $a$ and a braking input $b$, making up the control vector $u=(a,b)$.\n",
    "\n",
    "The dynamics of the car can then be written as\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\dot{\\lambda} & = v, \\\\\n",
    "    \\dot{v} & = 5a - 6.6 b v - 0.01 v^3,\n",
    "\\end{align*}\n",
    "$$\n",
    "where the cubic term corresponds to a viscous friction coming from the track surface and air resistance.\n",
    "We will denote this continuous-time dynamics as $\\dot{x} = f(x,u)$.\n",
    "\n",
    "Your goal in this notebook will be to implement a Nonlinear Model Predictive Control (NMPC) scheme to control the car around the track while avoiding flipping out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e279de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import casadi as ca\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from ipywidgets import interact\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a1844",
   "metadata": {},
   "source": [
    "## Problem 1: Discretization of the dynamics\n",
    "\n",
    "Recall that for a given initial time $t_0$ and an integration step $h$, the state at time $t_0+h$ is given by $$ x(t_0+h) = \\int_{0}^{h} f(x(t_0+s),u(t_0+s)) ds. $$\n",
    "\n",
    "There are several methods for aproximating this integration for a constant input (i.e. when $u(t_0+s) = u(t_0)$ for all $s\\in[0,h]$), like Euler and Runge-Kutta methods.\n",
    "\n",
    "### Task 1\n",
    "Implement Euler and 4th order Runge-Kutta (RK4) discretization methods to define the discrete-time dynamics $ x_{k+1} = f_d(x_k,u_k) $.\n",
    "Test your integrators with the initial conditions $x(t_0) = (0, 0.5), u(t_0) = (0.0, 0.2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, u):\n",
    "    return np.array([x[1], 5 * u[0] - 6.6 * u[1] * x[1] - 0.01 * x[0] ** 3])\n",
    "\n",
    "\n",
    "def euler(f, x, u, h):\n",
    "    # TODO: ------------------\n",
    "\t# TODO: add your code here\n",
    "    return ...\n",
    "\t# TODO: ------------------\n",
    "\n",
    "\n",
    "def rk4(f, x, u, h):\n",
    "    # TODO: ------------------\n",
    "\t# TODO: add your code here\n",
    "    \n",
    "\treturn ...\n",
    "    # TODO: ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.0, 0.5])\n",
    "u0 = np.array([0.0, 0.2])\n",
    "h = 0.01\n",
    "print(\"The next state computed from Euler integrator is: \", euler(f, x0, u0, h))\n",
    "print(\"The next state computed from RK4 integrator is: \", rk4(f, x0, u0, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564d0a1",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "For $x(0)=(0,0.5)$ and $u(t)=(0,0.2)$, simulate the system for 10 seconds with both integrators for $h=0.1s$ and $h=0.5s$.\n",
    "Plot and compare the resulting trajectories with the ones given by the `ode45` integrator defined for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode45(f, x, u, h):\n",
    "    return solve_ivp(lambda t, x: f(x, u), [0, h], x, method='RK45').y[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899df134",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.0, 0.5])\n",
    "u0 = np.array([0.0, 0.2])\n",
    "Tsim = 10\n",
    "for h in [0.1, 0.5]:\n",
    "    Nsim = int(Tsim / h)\n",
    "    x_euler = np.zeros((Nsim + 1, 2))\n",
    "    x_euler[0] = x0\n",
    "    x_rk4 = np.zeros((Nsim + 1, 2))\n",
    "    x_rk4[0] = x0\n",
    "    x_ode45 = np.zeros((Nsim + 1, 2))\n",
    "    x_ode45[0] = x0\n",
    "    t = np.linspace(0, Tsim, Nsim + 1)\n",
    "    for i in range(Nsim):\n",
    "        # TODO: -------------------------------------\n",
    "        # TODO: simulate one step with each integrator\n",
    "        x_rk4[i + 1] = ...\n",
    "        x_euler[i + 1] = ...\n",
    "        x_ode45[i + 1] = ...\n",
    "        # TODO: -------------------------------------\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.suptitle(rf\"Simulation for $h = {h}$\")\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(r\"$v$\")\n",
    "    plt.plot(t, x_rk4[:, 0], label=\"RK4\")\n",
    "    plt.plot(t, x_euler[:, 0], label=\"Euler\")\n",
    "    plt.plot(t, x_ode45[:, 0], label=\"ODE45\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title(r\"$\\lambda$\")\n",
    "    plt.plot(t, x_rk4[:, 1], label=\"RK4\")\n",
    "    plt.plot(t, x_euler[:, 1], label=\"Euler\")\n",
    "    plt.plot(t, x_ode45[:, 1], label=\"ODE45\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe1d83",
   "metadata": {},
   "source": [
    "## Problem 2: Compute jacobians with CasADi\n",
    "\n",
    "To implement the NMPC controller in the following problem, you will need a way to compute the derivatives used in the optimization algorithm.\n",
    "\n",
    "To avoid deriving the formulae by hand, we will use [CasADi](https://web.casadi.org/), a library that allows you to define symbolic expressions and compute their derivatives using algorithmic differentiation.\n",
    "\n",
    "We highly recommend reading the [CasADi documentation](https://web.casadi.org/docs/), in particular: \n",
    "- [section 3.1](https://web.casadi.org/docs/#the-sx-symbolics) describing the main symbolic type you will use (`ca.SX`)\n",
    "- [section 3.6](https://web.casadi.org/docs/#arithmetic-operations) and [3.7](https://web.casadi.org/docs/#querying-properties) describing the main operations you will use on them\n",
    "- [section 3.9](https://web.casadi.org/docs/#calculus-algorithmic-differentiation) describing how to perform algorithmic differentiation to compute derivatives of functions\n",
    "- [section 4-4.1](https://web.casadi.org/docs/#document-function) describing how to wrap your expressions into callable functions\n",
    "\n",
    "If you have a doubt about how a certain function works, either try to find an example in the previous page, or look for it in the [CasADi API reference](https://web.casadi.org/python-api/).\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Your goal is to compute the jacobians of the continuous dynamics $f$ with respect to the state and input:\n",
    "$$ \\frac{\\partial f}{\\partial x} \\quad \\text{and} \\quad \\frac{\\partial f}{\\partial u}. $$\n",
    "\n",
    "Implement two versions for each: \n",
    "- one using a finite difference approximation,\n",
    "- one using CasADi's algorithmic differentiation capabilities.\n",
    "\n",
    "Compare the errors between the two at the points $x=(0, 0.5), u=(0,0.2)$.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "- Recall that the finite difference approximation for the Jacobian is given by\n",
    "\t$$ \\frac{\\partial f}{\\partial x} \\approx \\frac{f(x + \\epsilon, u) - f(x - \\epsilon, u)}{2 \\epsilon}, $$\n",
    "\n",
    "\tand you can use a small value for $\\epsilon$, e.g. $10^{-6}$.\n",
    "\n",
    "- For the CasADi implementation, you will need to define symbolic variables for the states and inputs using `ca.SX.sym`, define the discrete dynamics using these symbolic variables, use `ca.jacobian` function to compute the derivatives, and wrap the resulting expressions into a `ca.Function` to evaluate them numerically.\n",
    "\n",
    "- You can call a `ca.Function` on a `np.ndarray`, but the result will be a special CasADi type `ca.DM` (corresponding to a 'Data Matrix', see [documentation Section 3.2](https://web.casadi.org/docs/#dm)) that you can convert to a `np.ndarray` using the `.toarray()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bfcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: ---------------------------------------------------------\n",
    "def jac_x_fd(x,u): \n",
    "\t# TODO: implement the finite difference Jacobian here\n",
    "    return ...\n",
    "\n",
    "\n",
    "def jac_u_fd(x,u):\n",
    "\t# TODO: implement the finite difference Jacobian here\n",
    "    return ...\n",
    "\n",
    "\n",
    "# TODO: implement CasADi versions of the Jacobians as ca.Function\n",
    "jac_x_casadi = ...\n",
    "jac_u_casadi = ...\n",
    "# TODO: ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.0, 0.5])\n",
    "u = np.array([0.0, 0.2])\n",
    "print(\"The Jacobian w.r.t x (finite differences):\\n\", jac_x_fd(x, u))\n",
    "print(\"The Jacobian w.r.t x (CasADi):\\n\", jac_x_casadi(x, u).toarray())\n",
    "print(\"The Jacobian w.r.t u (finite differences):\\n\", jac_u_fd(x, u))\n",
    "print(\"The Jacobian w.r.t u (CasADi):\\n\", jac_u_casadi(x, u).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfe609",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Linearize $f$ around a point $\\hat{x},\\hat{u}$ using both your finite difference and CasADi jacobians to compute the following approximation:\n",
    "$$ f_{lin}(x,u) = f(\\hat{x},\\hat{u}) + \\frac{\\partial f}{\\partial x}(\\hat{x},\\hat{u})(x - \\hat{x}) + \\frac{\\partial f}{\\partial u}(\\hat{x},\\hat{u})(u - \\hat{u}). $$\n",
    "\n",
    "Simulate the nonlinear system $f$ and the linearized system $f_{lin}$ using the RK4 integrator you implemented in Problem 1.\n",
    "Use $\\hat{x}=(0,0), \\hat{u}=(0,0)$ as the linearization point, and simulate both systems for 10 seconds starting from $x(0)=(0,0.5)$ and using a constant input $u(t)=(0, 0.2)$ using a time step of $h=0.5s$.\n",
    "\n",
    "Try changing the linearization point to $\\hat{x}=(0,0), \\hat{u}=(0,0.2)$ and observe the differences in the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254510d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat = np.array([0.0, 0.0])\n",
    "uhat = np.array([0.0, 0.0])\n",
    "# TODO: ------------------------\n",
    "# TODO: compute A and B matrices\n",
    "A = ...\n",
    "B = ...\n",
    "# TODO: ------------------------\n",
    "\n",
    "def linearized_dynamics(x, u):\n",
    "    return A @ x + B @ u\n",
    "\n",
    "\n",
    "x0 = np.array([0.0, 0.5])\n",
    "u0 = np.array([0.0, 0.2])\n",
    "Tsim = 10\n",
    "h = 0.5\n",
    "Nsim = int(Tsim / h)\n",
    "x_nonlinear = np.zeros((Nsim + 1, 2))\n",
    "x_nonlinear[0] = x0\n",
    "x_linear = np.zeros((Nsim + 1, 2))\n",
    "x_linear[0] = x0\n",
    "t = np.linspace(0, Tsim, Nsim + 1)\n",
    "for i in range(Nsim):\n",
    "    # TODO: ---------------------------------------\n",
    "    # TODO: simulate one step with each integrator\n",
    "    x_nonlinear[i + 1] = ...\n",
    "    x_linear[i + 1] = ...\n",
    "    # TODO: ---------------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.suptitle(rf\"Simulation for $h = {h}$\")\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(r\"$v$\")\n",
    "plt.plot(t, x_nonlinear[:, 0], label=\"nonlinear\")\n",
    "plt.plot(t, x_linear[:, 0], label=\"linear\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(r\"$\\lambda$\")\n",
    "plt.plot(t, x_nonlinear[:, 1], label=\"nonlinear\")\n",
    "plt.plot(t, x_linear[:, 1], label=\"linear\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb6d97",
   "metadata": {},
   "source": [
    "## Problem 3: Nonlinear Model Predictive Control\n",
    "\n",
    "Now that you know more about how to discretize the dynamics and how CasADi's symbolic differentiation works, you are ready to implement the NMPC controller.\n",
    "\n",
    "To formulate the optimization problem in a simple way, we will need the `ca.Opti` class.\n",
    "We recommend reading the [documentation](https://web.casadi.org/docs/#document-opti) to have a good overview of its capabilities.\n",
    "\n",
    "You will find below some utility functions for generating a track and for plotting the NMPC predictions or the closed-loop trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45298a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_track(track_type: str) -> dict[str, ca.Function]:\n",
    "    s = ca.SX.sym(\"s\")\n",
    "    if track_type == \"simple\":\n",
    "        pos = ca.Function(\n",
    "            \"pos\",\n",
    "            [s],\n",
    "            [ca.vertcat(np.pi * ca.sin(2 * np.pi * s), ca.sin(4 * np.pi * s))],\n",
    "        )\n",
    "    elif track_type == \"complex\":\n",
    "        wx = np.random.randn(3)\n",
    "        wy = np.random.randn(3)\n",
    "        pos = ca.Function(\n",
    "            \"pos\",\n",
    "            [s],\n",
    "            [\n",
    "                ca.vertcat(\n",
    "                    wx[0] * ca.sin(2 * np.pi * s)\n",
    "                    + wx[1] * ca.sin(4 * np.pi * s)\n",
    "                    + wx[2] * ca.sin(6 * np.pi * s),\n",
    "                    wy[0] * ca.sin(2 * np.pi * s)\n",
    "                    + wy[1] * ca.sin(4 * np.pi * s)\n",
    "                    + wy[2] * ca.sin(6 * np.pi * s),\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown track type: {track_type}\")\n",
    "\n",
    "    dpos = ca.jacobian(pos(s), s)\n",
    "    ddpos = ca.jacobian(dpos, s)\n",
    "\n",
    "    tangent = ca.Function(\"tangent\", [s], [dpos / ca.norm_2(dpos)])\n",
    "    normal = ca.Function(\n",
    "        \"normal\", [s], [ca.vertcat(-dpos[1], dpos[0]) / ca.norm_2(dpos)]\n",
    "    )\n",
    "\n",
    "    curvature = ca.Function(\n",
    "        \"curvature\",\n",
    "        [s],\n",
    "        [ca.fabs((dpos[0] * ddpos[1] - dpos[1] * ddpos[0]) / ca.norm_2(dpos) ** 3)],\n",
    "    )\n",
    "\n",
    "    maxspeed = ca.Function(\"maxspeed\", [s], [1 / (1 + curvature(s))])\n",
    "    spd = maxspeed(np.linspace(0, 1, 100000)).toarray()\n",
    "    mx, mn = np.max(spd), np.min(spd)\n",
    "    a = 0.9 / (mx - mn)\n",
    "    b = 0.1 - a * mn\n",
    "    maxspeed = ca.Function(\"maxspeed\", [s], [a / (1 + curvature(s)) / mx + b])\n",
    "\n",
    "    svals = np.linspace(0, 1, 100000)\n",
    "    posvals = pos(svals.reshape(1, -1)).toarray()\n",
    "    width = 0.05 * (np.max(posvals) - np.min(posvals))\n",
    "\n",
    "    # compute arc length parametrization\n",
    "\n",
    "    # lam is the arc length. We need a function lambda -> s\n",
    "    # => 1. evaluate lam at different s values\n",
    "    # => 2. Since the the sequences are monotonous the inverse mapping is trivial\n",
    "    # => 3. Create a linear spline (using ca.interpolant)\n",
    "    diffs = np.linalg.norm(np.diff(posvals, axis=1), axis=0)\n",
    "    lams = np.insert(np.cumsum(diffs), 0, 0.0)\n",
    "    lams = lams / lams[-1]  # normalized distance\n",
    "    param = ca.interpolant(\"param\", \"bspline\", [lams], svals)\n",
    "\n",
    "    # convert all previous functions into functions of lam\n",
    "    lam = ca.SX.sym(\"lam\")\n",
    "\n",
    "    return {\n",
    "        # used for mpc\n",
    "        \"maxspeed\": ca.Function(\"maxspeed\", [s], [maxspeed(s)]),\n",
    "        # used for plotting\n",
    "        \"param\": param,\n",
    "        \"pos\": ca.Function(\"pos\", [lam], [pos(param(lam))]),\n",
    "        \"tangent\": ca.Function(\"tangent\", [lam], [tangent(param(lam))]),\n",
    "        \"normal\": ca.Function(\"normal\", [lam], [normal(param(lam))]),\n",
    "        \"curvature\": ca.Function(\"curvature\", [lam], [curvature(param(lam))]),\n",
    "        \"width\": width,\n",
    "    }\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "def plot_curves(\n",
    "    track: dict[str, ca.Function],\n",
    "    lam: np.ndarray,\n",
    "    speed: np.ndarray,\n",
    "    accel: np.ndarray,\n",
    "    brake: np.ndarray,\n",
    "    epsilon_speed: np.ndarray,\n",
    "    title: str,\n",
    "):\n",
    "    t = h * np.arange(len(lam))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.plot(t, track[\"maxspeed\"](lam), \"k--\", linewidth=2, label=\"max speed\")\n",
    "    plt.plot(t, lam, linewidth=2, label=\"lam\")\n",
    "    plt.plot(t, speed, linewidth=2, label=\"speed\")\n",
    "    plt.step(t, np.append(accel, accel[-1]), linewidth=2, label=\"accel\", where=\"post\")\n",
    "    plt.step(t, -np.append(brake, brake[-1]), linewidth=2, label=\"brake\", where=\"post\")\n",
    "    plt.fill_between(t, speed-epsilon_speed, speed, color=\"gray\", alpha=0.5, label=\"speed margin\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_track( track: dict[str, ca.Function], lam: np.ndarray, lam_predictions: np.ndarray):\n",
    "    # Generate track points for visualization\n",
    "    lam_track = np.linspace(0, 1, 500)[None,:]\n",
    "    track_pos = track[\"pos\"](lam_track).toarray()\n",
    "    track_maxspeed = track[\"maxspeed\"](lam_track).toarray().flatten()\n",
    "    \n",
    "    def plot_at_timestep(k):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        \n",
    "        # Plot track with color indicating max speed\n",
    "        scatter = ax.scatter(\n",
    "            track_pos[0, :], \n",
    "            track_pos[1, :], \n",
    "            c=track_maxspeed, \n",
    "            cmap='RdYlGn', \n",
    "            s=20, \n",
    "            alpha=0.6,\n",
    "            label='Track'\n",
    "        )\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Max Speed', rotation=270, labelpad=20)\n",
    "        \n",
    "        # Plot current car position\n",
    "        car_pos = track[\"pos\"](lam[k]).toarray()\n",
    "        ax.plot(car_pos[0], car_pos[1], 'bo', markersize=15, label='Car Position', zorder=5)\n",
    "        \n",
    "        # Plot NMPC predictions (white points)\n",
    "        if k < lam_predictions.shape[1]:\n",
    "            pred_positions = track[\"pos\"](lam_predictions[:, k:k+1].T).toarray()\n",
    "            ax.plot(pred_positions[0, :], pred_positions[1, :], 'wo', \n",
    "                   markersize=6, markeredgecolor='black', markeredgewidth=1,\n",
    "                   label='NMPC Predictions', zorder=4)\n",
    "            # Connect predictions with a line\n",
    "            ax.plot(pred_positions[0, :], pred_positions[1, :], 'w--', \n",
    "                   linewidth=1.5, alpha=0.7, zorder=3)\n",
    "        \n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.set_title(f'Track Visualization - Time Step {k} (t = {k*h:.3f}s)')\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.axis('equal')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Create interactive slider\n",
    "    interact(plot_at_timestep, k=(0, len(lam)-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "h = 0.025\n",
    "track = generate_track(\"simple\")\n",
    "# track = generate_track(\"complex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73be258",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "The NMPC we will implement is the following\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\min_{x_i, u_i, \\epsilon_i} \\quad & \\sum_{k=0}^{N-1} \\left(-10 v_k + 0.1 a_k^2 + 1000 b_k^2 + 10000 (\\epsilon_k^2 + \\epsilon_k) \\right) - 10v_N+10000(\\epsilon_N^2 + \\epsilon_N) \\\\\n",
    "\\text{s.t.} \\quad & x_0 = x_{init},\\\\\n",
    "& x_{k+1} = f_d(x_k, u_k), \\quad k=0,\\ldots,N-1, \\\\\n",
    "& v_k \\leq \\bar{v}(\\lambda_k) + \\epsilon_k, \\quad k=0,\\ldots,N,\\\\\n",
    "& \\epsilon_k \\geq 0, \\quad k=0,\\ldots,N,\\\\\n",
    "& 0 \\leq a_k,b_k \\leq 1, \\quad k=0,\\ldots,N-1,\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note the following:\n",
    "- the cost function has a negative coefficient on the velocity to maximize it, and some small penalties on the acceleration and braking inputs to avoid aggressive maneuvers.\n",
    "- the velocity upper bound is given by the function $\\bar{v}$ that depends on the track. In the code you can access it using `track[\"maxspeed\"](lam)` where `lam` is a CasADi symbolic variable or a numpy array. \n",
    "- this constraint is softened using a slack variable $\\epsilon_k$ to ensure feasibility of the optimization problem at all times. A high penalty is added to the cost function to discourage the use of this slack variable.\n",
    "\n",
    "Your task is to complete the `create_nmpc` function below by implementing the constraints of our NMPC problem.\n",
    "A lot has been implemented for you, but we still encourage you to read the whole function and try to understand it.\n",
    "\n",
    "Quickly test your implementation by looking at the open-loop prediction for a single initial state $x_{init}=(0,0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2bf24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_d_casadi(x, u):\n",
    "    return rk4(f_casadi, x, u, h)\n",
    "\n",
    "\n",
    "def create_nmpc():\n",
    "    opti = ca.Opti()\n",
    "\n",
    "    # decision variables\n",
    "    X = opti.variable(2, N + 1)\n",
    "    U = opti.variable(2, N)\n",
    "\n",
    "    X0 = opti.parameter(2, 1)\n",
    "    lam0 = X0[0]\n",
    "    v0 = X0[1]\n",
    "\n",
    "    lam = X[0, :]\n",
    "    speed = X[1, :]\n",
    "    accel = U[0, :]\n",
    "    brake = U[1, :]\n",
    "\n",
    "    epsilon_speed = opti.variable(1, N + 1)  # slack variable for speed constraint\n",
    "\n",
    "    # objective function\n",
    "    opti.minimize(\n",
    "        # max velocity\n",
    "        -10 * ca.sum(speed)\n",
    "        # minimize acceleration\n",
    "        + 0.1 * accel @ accel.T\n",
    "        # minimize braking\n",
    "        + 1000 * brake @ brake.T\n",
    "        # L1 and L2 penalties on slack variables\n",
    "        + 10000 * ((epsilon_speed @ epsilon_speed.T) + ca.sum(epsilon_speed))\n",
    "    )\n",
    "\n",
    "\t# TODO: ---------------------------------------\n",
    "    # TODO: initial conditions\n",
    "    opti.subject_to(...)\n",
    "\n",
    "    # TODO: dynamics constraints (write the dynamics constraints as a function of X[:, k], U[:, k] and X[:, k + 1])\n",
    "    for k in range(N):\n",
    "        opti.subject_to(...)\n",
    "\n",
    "    # TODO: velocity constraints\n",
    "    opti.subject_to(...)\n",
    "\n",
    "    # TODO: input constraints\n",
    "    opti.subject_to(...)\n",
    "\n",
    "    # TODO: slack variable constraints\n",
    "    opti.subject_to(...) \n",
    "    # TODO: ---------------------------------------\n",
    "\n",
    "    # set solver\n",
    "    options = {\n",
    "        \"print_time\": False,\n",
    "        \"ipopt\": {\"sb\": \"yes\", \"print_level\": 0, \"tol\": 1e-3},\n",
    "    }\n",
    "    opti.solver(\"ipopt\", options)\n",
    "\n",
    "    return {\n",
    "        # solver instance\n",
    "        \"opti\": opti,\n",
    "        # optimization variables\n",
    "        \"X\": X,\n",
    "        \"U\": U,\n",
    "        \"epsilon_speed\": epsilon_speed,\n",
    "        # optimization parameters\n",
    "        \"X0\": X0,\n",
    "        # convenience variables\n",
    "        \"lam\": lam,\n",
    "        \"speed\": speed,\n",
    "        \"accel\": accel,\n",
    "        \"brake\": brake,\n",
    "        \"lam0\": lam0,\n",
    "        \"v0\": v0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30354df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter values\n",
    "nmpc = create_nmpc()\n",
    "nmpc[\"opti\"].set_value(nmpc[\"lam0\"], ...)\n",
    "nmpc[\"opti\"].set_value(nmpc[\"v0\"], ...)\n",
    "# solve the problem\n",
    "sol = nmpc[\"opti\"].solve()\n",
    "\n",
    "plot_curves(\n",
    "    track,\n",
    "    sol.value(nmpc[\"lam\"]),\n",
    "    sol.value(nmpc[\"speed\"]),\n",
    "    sol.value(nmpc[\"accel\"]),\n",
    "    sol.value(nmpc[\"brake\"]),\n",
    "    sol.value(nmpc[\"epsilon_speed\"]),\n",
    "    \"Open loop prediction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad536df7",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Now, you will test your controller in a closed-loop simulation around the racing track. Complete the code below to specify the current state, call the solver and extract the optimal control to apply to the system.\n",
    "\n",
    "In the plots below you will see the evolution of each state and control throughout the simulation, as well as the position open-loop predictions of the NMPC at each time step.\n",
    "\n",
    "If you go back a few cells and generate a 'complex' track, you should see that the velocity constraint is sometimes violated. Try tuning the cost function weights to reduce this effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd1ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closed loop simulation\n",
    "states = [np.array([0.0, 0.0])]\n",
    "controls = []\n",
    "epsilon_speed = [0.0]\n",
    "lam_predictions = []\n",
    "i = 0\n",
    "while states[-1][0] < 1:  # take one loop around the track\n",
    "    i += 1\n",
    "\n",
    "\t# TODO: --------------------------------\n",
    "    # TODO: update MPC params and solve it\n",
    "    nmpc[\"opti\"].set_value(...)\n",
    "    sol = ...\n",
    "    u_mpc = np.array(...)\n",
    "    # TODO: --------------------------------\n",
    "\n",
    "    # simulate next step and log values\n",
    "    controls.append(u_mpc)\n",
    "    states.append(f_d_casadi(states[-1], controls[-1]).toarray())\n",
    "    epsilon_speed.append(sol.value(nmpc[\"epsilon_speed\"][0]))\n",
    "    lam_predictions.append(sol.value(nmpc[\"lam\"]))\n",
    "\n",
    "states = np.column_stack(states)\n",
    "controls = np.column_stack(controls)\n",
    "epsilon_speed = np.array(epsilon_speed)\n",
    "lam_predictions = np.column_stack(lam_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot closed loop results\n",
    "plot_curves(\n",
    "    track,\n",
    "    states[0],\n",
    "    states[1],\n",
    "    controls[0],\n",
    "    controls[1],\n",
    "    epsilon_speed,\n",
    "    \"Closed loop simulation\",\n",
    ")\n",
    "plot_track(track, states[0], lam_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
